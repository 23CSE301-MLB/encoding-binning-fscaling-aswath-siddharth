{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUB9NTT_j2M5"
   },
   "outputs": [],
   "source": [
    "# Machine Learning Data Preprocessing Lab - Week 3\n",
    "# Topics: Missing Data Handling, Feature Scaling, Encoding, Binning, Normalization, Standardization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxCM_LJcmFbs"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-0X9jqqEmK-l"
   },
   "outputs": [],
   "source": [
    "df_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyK0FOLep6rW"
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "df_missing = create_sample_data_with_missing()\n",
    "print(\"Original dataset with missing values:\")\n",
    "print(df_missing)\n",
    "print(f\"\\nMissing values count:\\n{df_missing.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-V3S-0jp-tQ"
   },
   "outputs": [],
   "source": [
    "# Method 1: Drop rows with missing values\n",
    "df_drop_rows = df_missing.dropna()\n",
    "print(f\"\\nAfter dropping rows with missing values: {df_drop_rows.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BU4h4qoqaGe"
   },
   "outputs": [],
   "source": [
    "df_drop_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x49OqpthqfO_"
   },
   "outputs": [],
   "source": [
    "# Method 2: Drop columns with missing values\n",
    "df_drop_cols = df_missing.dropna(axis=1)\n",
    "df_drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sEIHXDKduzRS"
   },
   "outputs": [],
   "source": [
    "# Method 3: Fill missing values with mean/mode\n",
    "df_fill_mean = df_missing.copy()\n",
    "# Fill numerical columns with mean\n",
    "numerical_cols = ['age', 'salary', 'experience', 'performance_score']\n",
    "for col in numerical_cols:\n",
    "    df_fill_mean[col].fillna(df_fill_mean[col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsXMOZoCu9BK"
   },
   "outputs": [],
   "source": [
    "df_fill_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVftx2hqvBJi"
   },
   "outputs": [],
   "source": [
    "# Fill categorical columns with mode\n",
    "df_fill_mean['department'].fillna(df_fill_mean['department'].mode()[0], inplace=True)\n",
    "print(f\"\\nAfter filling with mean/mode:\")\n",
    "df_fill_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4rvEBsMvMD6"
   },
   "outputs": [],
   "source": [
    "# Method 4: Forward fill and backward fill\n",
    "df_ffill = df_missing.fillna(method='ffill')\n",
    "df_bfill = df_missing.fillna(method='bfill')\n",
    "df_ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtEzTuJNvVoL"
   },
   "outputs": [],
   "source": [
    "df_bfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnCJrEVPvcxL"
   },
   "outputs": [],
   "source": [
    "# Method 5: Using SimpleImputer\n",
    "imputer_mean = SimpleImputer(strategy='mean')\n",
    "imputer_mode = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "df_imputed = df_missing.copy()\n",
    "df_imputed[numerical_cols] = imputer_mean.fit_transform(df_imputed[numerical_cols])\n",
    "df_imputed[['department']] = imputer_mode.fit_transform(df_imputed[['department']])\n",
    "print(f\"\\nAfter SimpleImputer:\")\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9R3F3ivXvvOn"
   },
   "outputs": [],
   "source": [
    "# Method 6: KNN Imputer (for numerical data)\n",
    "knn_imputer = KNNImputer(n_neighbors=2)\n",
    "df_knn = df_missing.copy()\n",
    "df_knn[numerical_cols] = knn_imputer.fit_transform(df_knn[numerical_cols])\n",
    "print(f\"\\nAfter KNN Imputer (numerical columns only):\")\n",
    "print(df_knn[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvKpdsq5v12U"
   },
   "outputs": [],
   "source": [
    "# Load sample dataset (Boston Housing - using alternative since it's deprecated)\n",
    "# Creating synthetic housing data\n",
    "np.random.seed(42)\n",
    "housing_data = pd.DataFrame({\n",
    "    'rooms': np.random.normal(6, 1.5, 100),\n",
    "    'age': np.random.uniform(1, 100, 100),\n",
    "    'distance': np.random.exponential(3, 100),\n",
    "    'tax_rate': np.random.uniform(200, 800, 100),\n",
    "    'price': np.random.normal(25, 10, 100)\n",
    "})\n",
    "\n",
    "print(\"Original housing dataset (first 5 rows):\")\n",
    "print(housing_data.head())\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(housing_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcldI78W1A5E"
   },
   "outputs": [],
   "source": [
    "housing_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xmPGsGdiwr61"
   },
   "outputs": [],
   "source": [
    "# Method 1: Min-Max Scaling (Normalization)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "housing_minmax = pd.DataFrame(\n",
    "    scaler_minmax.fit_transform(housing_data),\n",
    "    columns=housing_data.columns\n",
    ")\n",
    "print(f\"\\nAfter Min-Max Scaling (0-1 range):\")\n",
    "print(housing_minmax.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rO1Z08D11byP"
   },
   "outputs": [],
   "source": [
    "housing_minmax.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPEv_YQU0BnH"
   },
   "outputs": [],
   "source": [
    "# Method 2: Standardization (Z-score normalization)\n",
    "scaler_standard = StandardScaler()\n",
    "housing_standard = pd.DataFrame(\n",
    "    scaler_standard.fit_transform(housing_data),\n",
    "    columns=housing_data.columns\n",
    ")\n",
    "print(f\"\\nAfter Standardization (mean=0, std=1):\")\n",
    "print(housing_standard.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-JKcU0Y1qPN"
   },
   "outputs": [],
   "source": [
    "housing_standard.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DaCcia_B0sJ2"
   },
   "outputs": [],
   "source": [
    "# Method 3: Robust Scaling (less sensitive to outliers)\n",
    "scaler_robust = RobustScaler()\n",
    "housing_robust = pd.DataFrame(\n",
    "    scaler_robust.fit_transform(housing_data),\n",
    "    columns=housing_data.columns\n",
    ")\n",
    "print(f\"\\nAfter Robust Scaling:\")\n",
    "print(housing_robust.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeXAG4ek0zSc"
   },
   "outputs": [],
   "source": [
    "# Method 5: Unit Vector Scaling (L2 normalization)\n",
    "from sklearn.preprocessing import normalize\n",
    "housing_unit = pd.DataFrame(\n",
    "    normalize(housing_data, norm='l2'),\n",
    "    columns=housing_data.columns\n",
    ")\n",
    "print(f\"\\nAfter Unit Vector Scaling:\")\n",
    "print(housing_unit.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zu-tW7JE16VU"
   },
   "outputs": [],
   "source": [
    "housing_unit.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sw2jOib77eeS"
   },
   "outputs": [],
   "source": [
    "# Create sample dataset with categorical variables\n",
    "categorical_data = pd.DataFrame({\n",
    "    'city': ['Mumbai', 'Delhi', 'Bangalore', 'Chennai', 'Mumbai', 'Delhi', 'Pune', 'Bangalore'],\n",
    "    'education': ['Graduate', 'Post-Graduate', 'Graduate', 'High School', 'Post-Graduate', 'Graduate', 'High School', 'Graduate'],\n",
    "    'experience_level': ['Junior', 'Senior', 'Mid', 'Junior', 'Senior', 'Mid', 'Junior', 'Senior'],\n",
    "    'salary_range': ['Low', 'High', 'Medium', 'Low', 'High', 'Medium', 'Low', 'High'],\n",
    "    'performance': [85, 92, 78, 65, 95, 82, 70, 88]\n",
    "})\n",
    "\n",
    "print(\"Original categorical dataset:\")\n",
    "categorical_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3l-ejvt7q3o"
   },
   "outputs": [],
   "source": [
    "# Method 1: Label Encoding (for ordinal data)\n",
    "le_education = LabelEncoder()\n",
    "le_experience = LabelEncoder()\n",
    "le_salary = LabelEncoder()\n",
    "\n",
    "categorical_label = categorical_data.copy()\n",
    "categorical_label['education_encoded'] = le_education.fit_transform(categorical_label['education'])\n",
    "categorical_label['experience_encoded'] = le_experience.fit_transform(categorical_label['experience_level'])\n",
    "categorical_label['salary_encoded'] = le_salary.fit_transform(categorical_label['salary_range'])\n",
    "\n",
    "print(f\"\\nAfter Label Encoding:\")\n",
    "print(categorical_label[['education', 'education_encoded', 'experience_level', 'experience_encoded']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmkLdUMk7wnY"
   },
   "outputs": [],
   "source": [
    "categorical_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clRq80Qh78FR"
   },
   "outputs": [],
   "source": [
    "# Method 2: One-Hot Encoding (for nominal data)\n",
    "categorical_onehot = pd.get_dummies(categorical_data, columns=['city', 'education'], prefix=['city', 'edu'])\n",
    "print(f\"\\nAfter One-Hot Encoding:\")\n",
    "print(categorical_onehot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMlYVkRO8BWx"
   },
   "outputs": [],
   "source": [
    "categorical_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxtxY2Wr8Z2a"
   },
   "outputs": [],
   "source": [
    "# Method 5: Ordinal Encoding (when order matters)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])\n",
    "salary_ordinal = ordinal_encoder.fit_transform(categorical_data[['salary_range']])\n",
    "print(f\"\\nOrdinal Encoding for 'salary_range':\")\n",
    "print(f\"Original: {categorical_data['salary_range'].tolist()}\")\n",
    "print(f\"Encoded: {salary_ordinal.flatten().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WX0WjktJ89N5"
   },
   "outputs": [],
   "source": [
    "categorical_data['salary_range'] = ordinal_encoder.fit_transform(categorical_data[['salary_range']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WYHswWE9OGT"
   },
   "outputs": [],
   "source": [
    "categorical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0KtXX3n-lIO"
   },
   "outputs": [],
   "source": [
    "# Create sample dataset for binning\n",
    "age_data = pd.DataFrame({\n",
    "    'age': [22, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 18, 28, 33, 38, 42, 48, 52, 58, 63],\n",
    "    'income': [30000, 45000, 60000, 75000, 80000, 90000, 95000, 100000, 85000, 70000,\n",
    "               60000, 25000, 50000, 70000, 78000, 85000, 92000, 98000, 88000, 75000]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOjBJGBk-nId"
   },
   "outputs": [],
   "source": [
    "age_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUapISDy-ocM"
   },
   "outputs": [],
   "source": [
    "# Method 1: Equal-width binning\n",
    "age_data['age_bins_equal'] = pd.cut(age_data['age'], bins=4, labels=['Young', 'Adult', 'Middle-aged', 'Senior'])\n",
    "print(f\"\\nEqual-width binning for age:\")\n",
    "print(age_data[['age', 'age_bins_equal']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E_Y_ac1-uil"
   },
   "outputs": [],
   "source": [
    "age_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TfzgSzE_I2g"
   },
   "outputs": [],
   "source": [
    "# Method 2: Equal-frequency binning (quantile-based)\n",
    "age_data['age_bins_quantile'] = pd.qcut(age_data['age'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "print(f\"\\nEqual-frequency binning for age:\")\n",
    "print(age_data[['age', 'age_bins_quantile']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_SDLkVm_h3S"
   },
   "outputs": [],
   "source": [
    "age_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPvu7bTJ_5qn"
   },
   "outputs": [],
   "source": [
    "custom_bins = [0, 30, 50, 70, 100]\n",
    "custom_labels = ['Youth', 'Young Adult', 'Middle Age', 'Senior']\n",
    "age_data['age_bins_custom'] = pd.cut(age_data['age'], bins=custom_bins, labels=custom_labels)\n",
    "print(f\"\\nCustom binning for age:\")\n",
    "print(age_data[['age', 'age_bins_custom']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iO6Kpi6N_8K7"
   },
   "outputs": [],
   "source": [
    "age_data.head(5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
